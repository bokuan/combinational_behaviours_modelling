{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from pyspark.sql import SparkSession\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.ops import unary_union\n",
    "sys.path.append(r'/mnt/vasp-got-da/scripts/team_data_analytics/josefin/adas_mtd/')\n",
    "import src.db.db_helper_dsl3 as dbh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sut': {'root': 's3a://vasp-got-da/data/spark/rwup/sut/',\n",
       "  'flc_obj': 's3a://vasp-got-da/data/spark/rwup/sut/record_id*flc*R5_object*',\n",
       "  'vehicle': 's3a://vasp-got-da/data/spark/rwup/sut/record_id*vehicle*'},\n",
       " 'avl_reference': {'root': 's3a://vasp-got-da/data/spark/rwup/avl_reference/',\n",
       "  'ego': 's3a://vasp-got-da/data/spark/rwup/avl_reference/record_id*_ego_df*',\n",
       "  'line': 's3a://vasp-got-da/data/spark/rwup/avl_reference/record_id*_line_df*',\n",
       "  'object': 's3a://vasp-got-da/data/spark/rwup/avl_reference/record_id*_object_df*'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = '../config.yaml'\n",
    "from scripts.dataloader import OnlineSpark\n",
    "session = OnlineSpark(config_path,size='large')\n",
    "session.path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ego_yaw(recording_id: str, time_interval: list=None) -> pd.DataFrame :\n",
    "    ego = session.loadParquet('avl_reference','ego',record_id=recording_id).select('ptp_time', 'Yaw', 'PositionX', 'PositionY')\n",
    "    if time_interval is not None:\n",
    "        sample_time_range = [pd.to_datetime(time_interval[0], unit='s'),\n",
    "                    pd.to_datetime(time_interval[1], unit='s')]\n",
    "        # print(sample_time_range)\n",
    "        lc_sample = ego.filter(ego.ptp_time.between(time_interval[0],time_interval[1])).toPandas()\n",
    "    else:        \n",
    "        lc_sample = ego.toPandas()\n",
    "    # lc_sample['ptp_time'] = pd.to_datetime(lc_sample['ptp_time'], unit='s')\n",
    "    return lc_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_line(recording_id: str, time_interval: list):\n",
    "    line = session.loadParquet('avl_reference','line',record_id=recording_id).select('ptp_time', 'BoundaryLineX', 'BoundaryLineY')\n",
    "    line_sample = line.filter(line.ptp_time.between(time_interval[0],time_interval[1])).toPandas()\n",
    "    return line_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lc(df, minimum=30, maximum=70):\n",
    "    matching_ptp_times = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        current_yaw = df.loc[i, 'Yaw']\n",
    "        current_ptp_time = df.loc[i, 'ptp_time']\n",
    "        found_matching_pair = False\n",
    "\n",
    "        # Check the next maximum rows\n",
    "        for j in range(i + 1, min(i + maximum + 1, len(df))):\n",
    "            if (abs(df.loc[j, 'Yaw'] - current_yaw) <= 0.001) and \\\n",
    "                (abs(df.loc[round((i+j)/2), 'Yaw'] - current_yaw)>0.015) and \\\n",
    "                (abs(df.loc[round((i+j)/2), 'Yaw'] - current_yaw)<0.1):\n",
    "                # Check if the matching row is within the range\n",
    "                if j >= i + minimum:\n",
    "                    matching_pair = (0.5*current_ptp_time-6+0.5*df.loc[j, 'ptp_time'], 0.5*current_ptp_time+6+0.5*df.loc[j, 'ptp_time'])\n",
    "                    matching_ptp_times.append(matching_pair)\n",
    "                    # print(matching_pair)\n",
    "                    i = i + 41 \n",
    "                    found_matching_pair = True\n",
    "                    break  # If a match is found, exit the inner loop\n",
    "                else:\n",
    "                    i += 1\n",
    "                    break\n",
    "\n",
    "        if not found_matching_pair:\n",
    "            i += 1   \n",
    "    return matching_ptp_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_cross(BoundaryX, BoundaryY, PositionX, PositionY, buffer_distance=0.1):\n",
    "    line_points = [(x, y) for x, y in zip(BoundaryX, BoundaryY)]\n",
    "    if len(line_points) < 2:\n",
    "        return False\n",
    "    boundary_line = LineString(line_points)\n",
    "    buffered_line = boundary_line.buffer(buffer_distance)\n",
    "    union_buffer = unary_union([buffered_line])\n",
    "    is_in_buffer = union_buffer.contains(Point(PositionX, PositionY))\n",
    "    return is_in_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, LineString\n",
    "from shapely.ops import unary_union\n",
    "def validate_lc(df, recording_id, lc_times, highway_time_interval):\n",
    "    filtered_lc = []\n",
    "    ego_sample = df\n",
    "    line_sample = load_line(recording_id, highway_time_interval)\n",
    "    for lc_time in lc_times:\n",
    "        for index, ego_position in ego_sample[(ego_sample['ptp_time']>=lc_time[0])&(ego_sample['ptp_time']<=lc_time[1])].iterrows():\n",
    "            PositionX = ego_position['PositionX']\n",
    "            PositionY = ego_position['PositionY']\n",
    "            ego_time = ego_position['ptp_time']\n",
    "            for idx, line in line_sample[line_sample['ptp_time']==ego_time].iterrows():\n",
    "                if if_cross(line['BoundaryLineX'], line['BoundaryLineY'], PositionX, PositionY):\n",
    "                    filtered_lc.append(lc_time)\n",
    "            break\n",
    "    return filtered_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1571 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 287/1571 [27:14<2:01:50,  5.69s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     ego_df \u001b[38;5;241m=\u001b[39m ego_df_whole[ego_df_whole[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mptp_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(time_interval[\u001b[38;5;241m0\u001b[39m],time_interval[\u001b[38;5;241m1\u001b[39m])]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m     lc1 \u001b[38;5;241m=\u001b[39m \u001b[43mfind_lc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mego_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     lc2 \u001b[38;5;241m=\u001b[39m validate_lc(ego_df, recording_id, lc1, time_interval)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lc2)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36mfind_lc\u001b[0;34m(df, minimum, maximum)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Check the next maximum rows\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mmin\u001b[39m(i \u001b[38;5;241m+\u001b[39m maximum \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mabs\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYaw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m current_yaw) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m     13\u001b[0m         (\u001b[38;5;28mabs\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mround\u001b[39m((i\u001b[38;5;241m+\u001b[39mj)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYaw\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m current_yaw)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.015\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m     14\u001b[0m         (\u001b[38;5;28mabs\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mround\u001b[39m((i\u001b[38;5;241m+\u001b[39mj)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYaw\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m current_yaw)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Check if the matching row is within the range\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m minimum:\n\u001b[1;32m     17\u001b[0m             matching_pair \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mcurrent_ptp_time\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[j, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mptp_time\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mcurrent_ptp_time\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m6\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[j, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mptp_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexing.py:1065\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1063\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlist\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m is_iterator(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1064\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_scalar_access\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexing.py:1156\u001b[0m, in \u001b[0;36m_LocIndexer._is_scalar_access\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(k, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m ax\u001b[38;5;241m.\u001b[39m_supports_partial_string_indexing:\n\u001b[1;32m   1152\u001b[0m         \u001b[38;5;66;03m# partial string indexing, df.loc['2000', 'A']\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;66;03m# should not be considered scalar\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_as_unique\u001b[49m:\n\u001b[1;32m   1157\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:6193\u001b[0m, in \u001b[0;36mIndex._index_as_unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6190\u001b[0m         missing \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(target), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n\u001b[1;32m   6191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m no_matches, missing\n\u001b[0;32m-> 6193\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   6194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_index_as_unique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   6195\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;124;03m    Whether we should treat this as unique for the sake of\u001b[39;00m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;124;03m    get_indexer vs get_indexer_non_unique.\u001b[39;00m\n\u001b[1;32m   6198\u001b[0m \n\u001b[1;32m   6199\u001b[0m \u001b[38;5;124;03m    For IntervalIndex compat.\u001b[39;00m\n\u001b[1;32m   6200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   6201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "highway_df = pd.read_csv('/home/a494189/vasp-got-da/scripts/team_data_analytics/Lingbin_Bokuan/Bokuan/road_type_motorway_interval_non_empty_filtered.csv')\n",
    "\n",
    "with tqdm(total=1571) as pbar_intervals:\n",
    "    out = []\n",
    "    for highway_index, highway_row in highway_df.iterrows():\n",
    "        try:\n",
    "            recording_id = highway_row[1]\n",
    "            time_intervals = ast.literal_eval(highway_row[2])\n",
    "            ego_df_whole = load_ego_yaw(recording_id)\n",
    "            for time_interval in time_intervals:\n",
    "                try:\n",
    "                    ego_df = ego_df_whole[ego_df_whole['ptp_time'].between(time_interval[0],time_interval[1])].reset_index(drop=True)\n",
    "                    lc1 = find_lc(ego_df)\n",
    "                    lc2 = validate_lc(ego_df, recording_id, lc1, time_interval)\n",
    "                    if len(lc2)>0:\n",
    "                        out.append([recording_id, lc2])\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping {recording_id} due to an error: {e}\")\n",
    "                pbar_intervals.update(1)\n",
    "        except AnalysisException as e:\n",
    "            print(f\"Skipping {recording_id} due to missing path: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['FM1073_20220606_140009', [(1654524227.41, 1654524239.41)]],\n",
       " ['FM1073_20220606_140009', [(1654526065.1100001, 1654526077.1100001)]],\n",
       " ['FM1073_20220315_130253', [(1647350154.3600001, 1647350166.3600001)]]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(out, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecording_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/a494189/vasp-got-da/scripts/team_data_analytics/Lingbin_Bokuan/Bokuan/lc.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(csv_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(out, columns=['recording_id', 'lc'])\n",
    "\n",
    "csv_file_path = '/home/a494189/vasp-got-da/scripts/team_data_analytics/Lingbin_Bokuan/Bokuan/lc.csv'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1571/1571 [2:57:42<00:00,  6.79s/it]  \n"
     ]
    }
   ],
   "source": [
    "def load_ego_yaw(recording_id: str, time_interval: list=None):\n",
    "    ego = session.loadParquet('avl_reference','ego',record_id=recording_id).select('ptp_time', 'Yaw', 'PositionX', 'PositionY')\n",
    "    if time_interval is not None:\n",
    "        ego = ego.filter((ego.ptp_time >= time_interval[0]) & (ego.ptp_time <= time_interval[1]))\n",
    "    return ego\n",
    "\n",
    "def load_line(recording_id: str, time_interval: list):\n",
    "    line = session.loadParquet('avl_reference','line',record_id=recording_id).select('ptp_time', 'BoundaryLineX', 'BoundaryLineY')\n",
    "    line = line.filter((line.ptp_time >= time_interval[0]) & (line.ptp_time <= time_interval[1]))\n",
    "    return line\n",
    "\n",
    "def find_lc(df, minimum=40, maximum=80):\n",
    "    df_pd = df.toPandas()\n",
    "    matching_ptp_times = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(df_pd):\n",
    "        current_yaw = df_pd.loc[i, 'Yaw']\n",
    "        current_ptp_time = df_pd.loc[i, 'ptp_time']\n",
    "        found_matching_pair = False\n",
    "\n",
    "        for j in range(i + 1, min(i + maximum + 1, len(df_pd))):\n",
    "            if (abs(df_pd.loc[j, 'Yaw'] - current_yaw) <= 0.001) and \\\n",
    "               (abs(df_pd.loc[round((i+j)/2), 'Yaw'] - current_yaw) > 0.013) and \\\n",
    "               (abs(df_pd.loc[round((i+j)/2), 'Yaw'] - current_yaw) < 0.2):\n",
    "                if j >= i + minimum:\n",
    "                    matching_pair = (0.5 * current_ptp_time - 6 + 0.5 * df_pd.loc[j, 'ptp_time'], 0.5 * current_ptp_time + 6 + 0.5 * df_pd.loc[j, 'ptp_time'])\n",
    "                    matching_ptp_times.append(matching_pair)\n",
    "                    i = i + 41\n",
    "                    found_matching_pair = True\n",
    "                    break\n",
    "                else:\n",
    "                    i += 1\n",
    "                    break\n",
    "\n",
    "        if not found_matching_pair:\n",
    "            i += 1\n",
    "\n",
    "    return matching_ptp_times\n",
    "\n",
    "def if_cross(BoundaryX, BoundaryY, PositionX, PositionY, buffer_distance=0.1):\n",
    "    line_points = [(x, y) for x, y in zip(BoundaryX, BoundaryY)]\n",
    "    if len(line_points) < 2:\n",
    "        return False\n",
    "    boundary_line = LineString(line_points)\n",
    "    buffered_line = boundary_line.buffer(buffer_distance)\n",
    "    union_buffer = unary_union([buffered_line])\n",
    "    return union_buffer.contains(Point(PositionX, PositionY))\n",
    "\n",
    "def validate_lc(df, recording_id, lc_times, highway_time_interval):\n",
    "    filtered_lc = []\n",
    "    line_sample = load_line(recording_id, highway_time_interval).toPandas()\n",
    "\n",
    "    for lc_time in lc_times:\n",
    "        ego_sample = df.filter((df.ptp_time >= lc_time[0]) & (df.ptp_time <= lc_time[1])).toPandas()\n",
    "        for _, ego_position in ego_sample.iterrows():\n",
    "            PositionX = ego_position['PositionX']\n",
    "            PositionY = ego_position['PositionY']\n",
    "            ego_time = ego_position['ptp_time']\n",
    "\n",
    "            for _, line in line_sample[line_sample['ptp_time'] == ego_time].iterrows():\n",
    "                if if_cross(line['BoundaryLineX'], line['BoundaryLineY'], PositionX, PositionY):\n",
    "                    filtered_lc.append(lc_time)\n",
    "            break\n",
    "\n",
    "    return filtered_lc\n",
    "\n",
    "highway_df = pd.read_csv('/home/a494189/vasp-got-da/scripts/team_data_analytics/Lingbin_Bokuan/Bokuan/road_type_motorway_interval_non_empty_filtered.csv')\n",
    "\n",
    "with tqdm(total=1571) as pbar_intervals:\n",
    "    out = []\n",
    "    for _, highway_row in highway_df.iterrows():\n",
    "        try:\n",
    "            recording_id = highway_row[1]\n",
    "            time_intervals = ast.literal_eval(highway_row[2])\n",
    "            ego_df_whole = load_ego_yaw(recording_id)\n",
    "            \n",
    "            for time_interval in time_intervals:\n",
    "                try:\n",
    "                    ego_df = ego_df_whole.filter((ego_df_whole.ptp_time >= (time_interval[0]-10)) & (ego_df_whole.ptp_time <= (time_interval[1]+10)))\n",
    "                    lc1 = find_lc(ego_df)\n",
    "                    lc2 = validate_lc(ego_df, recording_id, lc1, time_interval)\n",
    "                    \n",
    "                    if lc2:\n",
    "                        out.append([recording_id, lc2])\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping {time_interval} in {recording_id} for: {e}\")\n",
    "                \n",
    "                pbar_intervals.update(1)\n",
    "        \n",
    "        except AnalysisException as e:\n",
    "            print(f\"Skipping {recording_id} for: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
